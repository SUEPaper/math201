---
id: lab7
sidebar_position: 7
---

# 实验7: 矩阵的特征值和特征向量实验

## 问题1：利用改进的幂法求矩阵按模最大特征值及对应的特征向量

**问题1**： 编写利用改进的幂法计算矩阵的主特征值和对应的特征向量的通用程序，并求出下面矩阵的输出将诶过，其中主特征值的计算精度为$\varepsilon=0.5\times 10^{-5}$。
$$
A=\begin{pmatrix}
  2 & 3 & 2 \\
  10 & 3 & 4 \\
  3& 6 & 1 \\
\end{pmatrix}
$$

**实验原理**：改进的幂法主要步骤为：任取非零向量$\mathbf{v}_0$，取$k=0$，
1. 求出$\mathbf{v}_k$中按模最大的分量为$p_k$，即$p_k=\|\mathbf{v}_k\|_{\infty}$；
2. 计算$\mathbf{u}_k=\dfrac{\mathbf{v}_k}{\|\mathbf{v}_k\|_{\infty}}$，迭代一次$\mathbf{v}_{k+1} = A \mathbf{u}_k$;
3. 计算$\mathbf{v}_{k+1}$按模最大的分量为$p_{k+1}$，若$|p_{k+1}-p_k|<\varepsilon$，则输出$p_{k+1}$为近似的主特征值$\lambda_1$，$\mathbf{u}_k$为特征值$\lambda_1$对应的近似特征向量，并停止迭代。否则，令$k=k+1$，转第2步。

> **定理**：设$A$有$n$个线性无关的特征向量，其特征值满足
> $$
> |\lambda_1|>|\lambda_2|\geq |\lambda_3|\geq \cdots \geq |\lambda_n|
> $$
> 对应的特征向量分别为$\mathbf{x}_1,$ $\mathbf{x}_2, \cdots,$  $\mathbf{x}_n$，则由上面改进的幂法生成的向量满足
> $$
> \lim_{k\rightarrow \infty}\mathbf{u}_k = \frac{\mathbf{x}_1}{\|\mathbf{x}_1\|_{\infty}}, \lim_{k\rightarrow \infty}\|\mathbf{v}_k\|_{\infty} = |\lambda_1|.
> $$
> 

**实验过程**：

```python
'''
利用改进的幂法求矩阵的主特征值和对应的特征向量
'''
import numpy as np

def improved_power_method(A, tol=0.5e-5):
    '''
    :param A: 方阵
    :param tol: 容许误差，计算精度
    :return: 主特征值近似值为Pk, 对应的特征向量uk
    '''
    A = np.array(A)            #转化为np.array()
    n = np.size(A, 1)          #矩阵的行数或列数
    v0 = np.ones((n, 1))       #迭代向量初始值
    p0 = np.max(np.abs(v0))    #v0的无穷范数，按模最大分量
    u0 = v0 / np.max(np.abs(v0)) #规范化
    v1 = np.matmul(A, u0)        #迭代计算一次得到v1
    p1 = np.max(np.abs(v1))      #主特征值近似值
    u1 = v1 / np.max(np.abs(v1)) #规范化
    k = 1 #迭代次数
    print(f'第{k}次迭代的主特征值为: {p1}')
    #判断是否满足精度要求
    while np.abs(p1 - p0) >tol:
        u0 = u1
        p0 = p1
        '''
        ------------------------------
        这里作为作业思考，请根据你的理解补充完整
        ------------------------------
        '''
        k += 1  # 更新迭代次数
        print(f'第{k}次迭代的主特征值为: {p1}')

    print('----' * 10)
    print(f'共迭代{k}次，求得的主特征值近似为: {p1}')
    print('相应的特征向量近似为')
    print(u1)
    return p1, u1


if __name__ == '__main__':
    #算例
    A = [[2.0, 3, 2],
         [10, 3, 4.0],
         [3, 6, 1]]
    tol = 0.5e-5 #容许误差，精度
    #调用改进的幂法求主特征值
    value1, vector1 = improved_power_method(A, tol=tol)
```

输出结果为

```python
第1次迭代的主特征值为: 17.0
第2次迭代的主特征值为: 9.470588235294118
第3次迭代的主特征值为: 11.58385093167702
第4次迭代的主特征值为: 10.831635388739945
第5次迭代的主特征值为: 11.049799514875502
第6次迭代的主特征值为: 10.985906091381928
第7次迭代的主特征值为: 11.003953118800313
第8次迭代的主特征值为: 10.998903290037243
第9次迭代的主特征值为: 11.000302582696586
第10次迭代的主特征值为: 10.999916852432536
第11次迭代的主特征值为: 11.000022790833176
第12次迭代的主特征值为: 10.999993763594336
第13次迭代的主特征值为: 11.000001704609195
第14次迭代的主特征值为: 10.999999534421143
----------------------------------------
共迭代14次，求得的主特征值近似为: 10.999999534421143
相应的特征向量近似为
[[0.5       ]
 [1.        ]
 [0.75000002]]
```

**结果分析**：计算得到的主特征值为$10.999999534421143$。实际上，该矩阵的特征值精确值为
$$
\lambda_1=11,\lambda_2=-3,\lambda_3=-2.
$$
由此可见，算例结果是有效的。

## 问题2：利用反幂法求矩阵按模最小的特征值及对应的特征向量

**问题2**： 编写利用反幂法计算矩阵的按模 最小特征值和对应的特征向量的通用程序，并求出下面矩阵的输出将诶过，其中主特征值的计算精度为$\varepsilon=0.5\times 10^{-5}$。
$$
A=\begin{pmatrix}
  2 & 3 & 2 \\
  10 & 3 & 4 \\
  3& 6 & 1 \\
\end{pmatrix}
$$

**动手实践和探讨分析**：请完成算法理论分析和动手编程实现，这里从略。